{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation d'image avec 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras.models as models\n",
    "#import keras.layers.containers as containers\n",
    "from keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape,  Permute\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'\n",
    "# os.environ['KERAS_BACKEND']=\"tensorflow\"\n",
    "# os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=gpu0,floatX=float32,optimizer=fast_compile'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"CamVid\")\n",
    "os.chdir(\"train\")\n",
    "train_images=os.listdir()\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"trainannot\")\n",
    "train_targets = os.listdir()\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classe : 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(367, 224, 224, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "for path_image in train_images:\n",
    "    img=plt.imread(\"./CamVid/train\"+\"/\"+path_image)\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    img = (img[:,:,0]+img[:,:,1]+img[:,:,2])/3\n",
    "    img = np.expand_dims(img,axis=2)\n",
    "    X_train.append(img)\n",
    "    img=cv2.imread(\"./CamVid/trainannot\"+\"/\"+path_image)\n",
    "    img=cv2.resize(img,(224,224))\n",
    "#     for i in range(img.shape[0]):\n",
    "#         for j in range(img.shape[1]):\n",
    "#             if \n",
    "    Y_train.append(np.expand_dims(np.concatenate(img[:,:,0]),axis=1))\n",
    "    \n",
    "#     img=cv2.resize(img,(224,224))\n",
    "Y_train=np.array(Y_train)\n",
    "X_train=np.array(X_train)\n",
    "nb_class=np.max(Y_train)+1-np.min(Y_train)\n",
    "print(\"Nombre de classe :\",nb_class)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "batch_size = 4\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Input features and output targets.\n",
    "features  = tf.placeholder(tf.float32,shape=[None,224,224,1])\n",
    "targets = tf.placeholder(tf.float32,shape=[None,224*224,1])\n",
    "with tf.name_scope('Iterator'):\n",
    "# Create separate Datasets for training and validation\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((features, targets))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=2000).batch(batch_size)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((features, targets))\n",
    "    val_dataset = val_dataset.batch(1)\n",
    "\n",
    "# Iterator has to have same output types across all Datasets to be used\n",
    "    iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "    images, labels = iterator.get_next()\n",
    "    \n",
    "# Initialize with required Datasets\n",
    "labels=tf.cast(labels,tf.int32)\n",
    "train_iterator = iterator.make_initializer(train_dataset)\n",
    "val_iterator = iterator.make_initializer(val_dataset)\n",
    "\n",
    "with tf.name_scope('fc1_CNN'):\n",
    "    fc1_conv = tf.layers.conv2d(images,filters=64, kernel_size=(5,5),padding='SAME')\n",
    "    fc1_conv = tf.layers.conv2d(fc1_conv,filters=64, kernel_size=(5,5),padding='SAME')\n",
    "    fc1_conv_norm = tf.layers.batch_normalization(fc1_conv, training=True)\n",
    "    fc1_relu = tf.nn.relu(fc1_conv_norm)\n",
    "    fc1_pool = tf.layers.max_pooling2d(inputs=fc1_relu, pool_size=(2,2), strides=(2,2))\n",
    "    \n",
    "with tf.name_scope('fc2_CNN'):\n",
    "    fc2_conv = tf.layers.conv2d(fc1_pool,filters=128, kernel_size=(3,3),padding='SAME')\n",
    "    fc2_conv = tf.layers.conv2d(fc2_conv,filters=128, kernel_size=(3,3),padding='SAME')\n",
    "    fc2_conv_norm = tf.layers.batch_normalization(fc2_conv, training=True)\n",
    "    fc2_relu = tf.nn.relu(fc2_conv_norm)\n",
    "    fc2_pool = tf.layers.max_pooling2d(inputs=fc2_relu, pool_size=(2,2), strides=(2,2))\n",
    "    \n",
    "with tf.name_scope('fc3_CNN'):\n",
    "    fc3_conv = tf.layers.conv2d(fc2_pool,filters=256, kernel_size=(3,3),padding='SAME')\n",
    "    fc3_conv = tf.layers.conv2d(fc3_conv,filters=256, kernel_size=(3,3),padding='SAME')\n",
    "    fc3_conv = tf.layers.conv2d(fc3_conv,filters=256, kernel_size=(3,3),padding='SAME')\n",
    "    fc3_conv_norm = tf.layers.batch_normalization(fc3_conv, training=True)\n",
    "    fc3_relu = tf.nn.relu(fc3_conv_norm)\n",
    "    fc3_pool = tf.layers.max_pooling2d(inputs=fc3_relu, pool_size=(2,2), strides=(2,2))\n",
    "    \n",
    "with tf.name_scope('fc4_CNN'):\n",
    "    fc4_conv = tf.layers.conv2d(fc3_pool,filters=512, kernel_size=(3,3),padding='SAME')\n",
    "    fc4_conv = tf.layers.conv2d(fc4_conv,filters=512, kernel_size=(3,3),padding='SAME')\n",
    "    fc4_conv = tf.layers.conv2d(fc4_conv,filters=512, kernel_size=(3,3),padding='SAME')\n",
    "    fc4_conv_norm = tf.layers.batch_normalization(fc4_conv, training=True)\n",
    "    fc4_relu = tf.nn.relu(fc4_conv_norm)\n",
    "    fc4_pool = tf.layers.max_pooling2d(inputs=fc4_relu, pool_size=(2,2), strides=(2,2))\n",
    "    \n",
    "with tf.name_scope('fc5_CNN'):\n",
    "    fc5_conv = tf.layers.conv2d(fc4_pool,filters=512, kernel_size=(3,3),padding='SAME')\n",
    "    fc5_conv = tf.layers.conv2d(fc5_conv,filters=512, kernel_size=(3,3),padding='SAME')\n",
    "    fc5_conv = tf.layers.conv2d(fc5_conv,filters=512, kernel_size=(3,3),padding='SAME')\n",
    "    fc5_conv_norm = tf.layers.batch_normalization(fc5_conv, training=True)\n",
    "    fc5_relu = tf.nn.relu(fc5_conv_norm)\n",
    "    fc5_pool = tf.layers.max_pooling2d(inputs=fc5_relu, pool_size=(2,2), strides=(2,2))\n",
    "    \n",
    "with tf.name_scope('de1_CNN'):\n",
    "    de1_ups=tf.image.resize_nearest_neighbor(fc5_pool, (2*7,2*7))\n",
    "    de1_conv = tf.layers.conv2d(de1_ups,filters=512, kernel_size=(3,3),padding='SAME')\n",
    "    de1_conv = tf.layers.conv2d(de1_conv,filters=512, kernel_size=(3,3),padding='SAME')\n",
    "    de1_conv = tf.layers.conv2d(de1_conv,filters=512, kernel_size=(3,3),padding='SAME')\n",
    "    de1_conv_norm = tf.layers.batch_normalization(de1_conv, training=True)\n",
    "    de1_relu = tf.nn.relu(de1_conv_norm)\n",
    "    \n",
    "    \n",
    "    \n",
    "with tf.name_scope('de2_CNN'):\n",
    "    de2_ups=tf.image.resize_nearest_neighbor(de1_relu, (2*14,2*14))\n",
    "    de2_conv = tf.layers.conv2d(de1_ups,filters=256, kernel_size=(3,3),padding='SAME')\n",
    "    de2_conv = tf.layers.conv2d(de2_conv,filters=256, kernel_size=(3,3),padding='SAME')\n",
    "    de2_conv = tf.layers.conv2d(de2_conv,filters=256, kernel_size=(3,3),padding='SAME')\n",
    "    de2_conv_norm = tf.layers.batch_normalization(de2_conv, training=True)\n",
    "    de2_relu = tf.nn.relu(de2_conv_norm)\n",
    "    \n",
    "    \n",
    "with tf.name_scope('de3_CNN'):\n",
    "    de3_ups=tf.image.resize_nearest_neighbor(de2_relu, (2*28,2*28))\n",
    "    de3_conv = tf.layers.conv2d(de3_ups,filters=128, kernel_size=(3,3),padding='SAME')\n",
    "    de3_conv = tf.layers.conv2d(de3_conv,filters=128, kernel_size=(3,3),padding='SAME')\n",
    "    de3_conv = tf.layers.conv2d(de3_conv,filters=128, kernel_size=(3,3),padding='SAME')\n",
    "    de3_conv_norm = tf.layers.batch_normalization(de3_conv, training=True)\n",
    "    de3_relu = tf.nn.relu(de3_conv_norm)\n",
    "\n",
    "with tf.name_scope('de4_CNN'):\n",
    "    de4_ups=tf.image.resize_nearest_neighbor(de3_relu, (2*56,2*56))\n",
    "    de4_conv = tf.layers.conv2d(de4_ups,filters=64, kernel_size=(3,3),padding='SAME')\n",
    "    de4_conv = tf.layers.conv2d(de4_conv,filters=64, kernel_size=(3,3),padding='SAME')\n",
    "    de4_conv_norm = tf.layers.batch_normalization(de4_conv, training=True)\n",
    "    de4_relu = tf.nn.relu(de4_conv_norm)\n",
    "\n",
    "with tf.name_scope('de5_CNN'):\n",
    "    de5_ups=tf.image.resize_nearest_neighbor(de4_relu, (2*112,2*112))\n",
    "    de5_conv = tf.layers.conv2d(de5_ups,filters=nb_class, kernel_size=(3,3),padding='SAME')\n",
    "    de5_conv = tf.layers.conv2d(de5_conv,filters=nb_class, kernel_size=(3,3),padding='SAME')\n",
    "    de5_conv_norm = tf.layers.batch_normalization(de5_conv, training=True)\n",
    "\n",
    "with tf.name_scope('reshape_CNN'):\n",
    "    reshape_CNN=tf.reshape(de5_conv_norm,[-1,224*224,12])\n",
    "    output = tf.nn.softmax(reshape_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Loss_function'):\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=output)\n",
    "\n",
    "with tf.name_scope('Optimizer'):\n",
    "    learning_rate=tf.placeholder(tf.float32)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope('Prediction'):\n",
    "    true_label = tf.argmax(input=labels, axis=2)\n",
    "    pred = tf.argmax(input=output, axis=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data load in iterator : 0.06800389289855957\n",
      "Epoch : 0  -- Time : 19.672125101089478\n",
      "Epoch : 0  -- Time : 39.15823984146118\n",
      "Cost : 2.4822288\n",
      "Epoch : 1  -- Time : 19.061090230941772\n",
      "Epoch : 2  -- Time : 18.917081832885742\n",
      "Epoch : 3  -- Time : 19.009087324142456\n",
      "Epoch : 4  -- Time : 18.97008514404297\n",
      "Epoch : 5  -- Time : 19.205098390579224\n",
      "Epoch : 5  -- Time : 38.4041965007782\n",
      "Cost : 2.3895566\n",
      "Epoch : 6  -- Time : 19.078091144561768\n",
      "Epoch : 7  -- Time : 18.899080991744995\n",
      "Epoch : 8  -- Time : 19.396109580993652\n",
      "Epoch : 9  -- Time : 19.110093116760254\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epoch=10\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#Load weight\n",
    "t0=time.time()\n",
    "sess.run(train_iterator, feed_dict = {features: X_train, targets: Y_train })\n",
    "print(\"Data load in iterator :\",time.time()-t0)\n",
    "\n",
    "for e in range(epoch):\n",
    "    t0=time.time()\n",
    "    sess.run([train_op],feed_dict={learning_rate:0.01})\n",
    "    print(\"Epoch :\",e,\" -- Time :\",time.time()-t0)\n",
    "    if (e%5==0):\n",
    "        _,cost = sess.run([train_op,loss],feed_dict={learning_rate:0.01})\n",
    "        print(\"Epoch :\",e,\" -- Time :\",time.time()-t0)\n",
    "        print(\"Cost :\",cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0  -- Time : 20.91619634628296\n",
      "Epoch : 0  -- Time : 40.778332471847534\n",
      "Cost : 2.0644944\n",
      "Epoch : 1  -- Time : 20.859193086624146\n",
      "Epoch : 2  -- Time : 19.419110774993896\n",
      "Epoch : 3  -- Time : 20.24715805053711\n",
      "Epoch : 4  -- Time : 21.412224769592285\n",
      "Epoch : 5  -- Time : 22.98531460762024\n",
      "Epoch : 5  -- Time : 45.798619508743286\n",
      "Cost : 2.0745468\n",
      "Epoch : 6  -- Time : 22.338277578353882\n",
      "Epoch : 7  -- Time : 20.101149797439575\n",
      "Epoch : 8  -- Time : 19.757129907608032\n",
      "Epoch : 9  -- Time : 20.16515326499939\n",
      "Epoch : 10  -- Time : 19.62012219429016\n",
      "Epoch : 10  -- Time : 38.757216691970825\n",
      "Cost : 2.0306807\n",
      "Epoch : 11  -- Time : 19.64612364768982\n",
      "Epoch : 12  -- Time : 20.820190906524658\n",
      "Epoch : 13  -- Time : 20.597177982330322\n",
      "Epoch : 14  -- Time : 20.298160791397095\n",
      "Epoch : 15  -- Time : 20.9982008934021\n",
      "Epoch : 15  -- Time : 41.714385747909546\n",
      "Cost : 2.0035183\n",
      "Epoch : 16  -- Time : 20.566176414489746\n",
      "Epoch : 17  -- Time : 20.497172117233276\n",
      "Epoch : 18  -- Time : 20.775188207626343\n",
      "Epoch : 19  -- Time : 19.978142738342285\n",
      "Epoch : 20  -- Time : 19.809133052825928\n",
      "Epoch : 20  -- Time : 39.79227614402771\n",
      "Cost : 2.0684147\n",
      "Epoch : 21  -- Time : 19.642123460769653\n",
      "Epoch : 22  -- Time : 20.034146070480347\n",
      "Epoch : 23  -- Time : 19.96014165878296\n",
      "Epoch : 24  -- Time : 19.62012243270874\n",
      "Epoch : 25  -- Time : 19.573119401931763\n",
      "Epoch : 25  -- Time : 38.900224924087524\n",
      "Cost : 2.013897\n",
      "Epoch : 26  -- Time : 19.582120180130005\n",
      "Epoch : 27  -- Time : 19.765130519866943\n",
      "Epoch : 28  -- Time : 19.59112048149109\n",
      "Epoch : 29  -- Time : 19.274102449417114\n",
      "Epoch : 30  -- Time : 19.685125827789307\n",
      "Epoch : 30  -- Time : 40.388309955596924\n",
      "Cost : 2.0804007\n",
      "Epoch : 31  -- Time : 20.873193740844727\n",
      "Epoch : 32  -- Time : 21.335220336914062\n",
      "Epoch : 33  -- Time : 21.187211990356445\n",
      "Epoch : 34  -- Time : 20.784188747406006\n",
      "Epoch : 35  -- Time : 20.291160583496094\n",
      "Epoch : 35  -- Time : 40.41431164741516\n",
      "Cost : 1.9372593\n",
      "Epoch : 36  -- Time : 20.901195526123047\n",
      "Epoch : 37  -- Time : 20.832191705703735\n",
      "Epoch : 38  -- Time : 20.230157136917114\n",
      "Epoch : 39  -- Time : 19.587120294570923\n",
      "Epoch : 40  -- Time : 20.02914571762085\n",
      "Epoch : 40  -- Time : 40.12029480934143\n",
      "Cost : 1.9956412\n",
      "Epoch : 41  -- Time : 19.54511785507202\n",
      "Epoch : 42  -- Time : 19.827134132385254\n",
      "Epoch : 43  -- Time : 19.774131059646606\n",
      "Epoch : 44  -- Time : 19.70112705230713\n",
      "Epoch : 45  -- Time : 19.8571355342865\n",
      "Epoch : 45  -- Time : 39.9712860584259\n",
      "Cost : 2.0154898\n",
      "Epoch : 46  -- Time : 19.68912625312805\n",
      "Epoch : 47  -- Time : 19.625122547149658\n",
      "Epoch : 48  -- Time : 20.053146839141846\n",
      "Epoch : 49  -- Time : 19.55111813545227\n",
      "Epoch : 50  -- Time : 19.302103996276855\n",
      "Epoch : 50  -- Time : 40.976343870162964\n",
      "Cost : 2.0317805\n",
      "Epoch : 51  -- Time : 20.278159856796265\n",
      "Epoch : 52  -- Time : 19.75012969970703\n",
      "Epoch : 53  -- Time : 19.869136333465576\n",
      "Epoch : 54  -- Time : 19.200098037719727\n",
      "Epoch : 55  -- Time : 19.14109468460083\n",
      "Epoch : 55  -- Time : 39.48225808143616\n",
      "Cost : 1.9312118\n",
      "Epoch : 56  -- Time : 20.963199138641357\n",
      "Epoch : 57  -- Time : 21.506230115890503\n",
      "Epoch : 58  -- Time : 20.29516077041626\n",
      "Epoch : 59  -- Time : 19.849135398864746\n",
      "Epoch : 60  -- Time : 20.401166915893555\n",
      "Epoch : 60  -- Time : 40.553319454193115\n",
      "Cost : 2.06759\n",
      "Epoch : 61  -- Time : 19.6411235332489\n",
      "Epoch : 62  -- Time : 20.654181480407715\n",
      "Epoch : 63  -- Time : 20.71218466758728\n",
      "Epoch : 64  -- Time : 20.94319796562195\n",
      "Epoch : 65  -- Time : 20.04914665222168\n",
      "Epoch : 65  -- Time : 40.34530758857727\n",
      "Cost : 1.9743977\n",
      "Epoch : 66  -- Time : 19.354106903076172\n",
      "Epoch : 67  -- Time : 19.21109890937805\n",
      "Epoch : 68  -- Time : 19.404109716415405\n",
      "Epoch : 69  -- Time : 19.746129512786865\n",
      "Epoch : 70  -- Time : 19.86513638496399\n",
      "Epoch : 70  -- Time : 39.19724202156067\n",
      "Cost : 1.9981192\n",
      "Epoch : 71  -- Time : 19.23110008239746\n",
      "Epoch : 72  -- Time : 20.49217200279236\n",
      "Epoch : 73  -- Time : 19.347106456756592\n",
      "Epoch : 74  -- Time : 19.10709309577942\n",
      "Epoch : 75  -- Time : 19.078091144561768\n",
      "Epoch : 75  -- Time : 34.17795467376709\n",
      "Cost : 1.8544102\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "End of sequence\n\t [[Node: Iterator/IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,1], [?,50176,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator/Iterator)]]\n\nCaused by op 'Iterator/IteratorGetNext', defined at:\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-2d177a19bd39>\", line 18, in <module>\n    images, labels = iterator.get_next()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 410, in get_next\n    name=name)), self._output_types,\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2069, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[Node: Iterator/IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,1], [?,50176,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator/Iterator)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[Node: Iterator/IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,1], [?,50176,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator/Iterator)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2268c9532214>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mt0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" -- Time :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[Node: Iterator/IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,1], [?,50176,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator/Iterator)]]\n\nCaused by op 'Iterator/IteratorGetNext', defined at:\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-2d177a19bd39>\", line 18, in <module>\n    images, labels = iterator.get_next()\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 410, in get_next\n    name=name)), self._output_types,\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2069, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Thomas\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[Node: Iterator/IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,1], [?,50176,1]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator/Iterator)]]\n"
     ]
    }
   ],
   "source": [
    "sess.run(train_iterator, feed_dict = {features: X_train, targets: Y_train })\n",
    "\n",
    "for e in range(100):\n",
    "    t0=time.time()\n",
    "    sess.run([train_op],feed_dict={learning_rate:0.01})\n",
    "    print(\"Epoch :\",e,\" -- Time :\",time.time()-t0)\n",
    "    if (e%5==0):\n",
    "        _,cost = sess.run([train_op,loss],feed_dict={learning_rate:0.01})\n",
    "        print(\"Epoch :\",e,\" -- Time :\",time.time()-t0)\n",
    "        print(\"Cost :\",cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to calculate 1 iteration : 1.783102035522461\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "z=sess.run(pred)\n",
    "print(\"Time to calculate 1 iteration :\",time.time()-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1=np.reshape(z[0],(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b381278>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('de2_CNN'):\n",
    "    de1_ups=tf.image.resize_nearest_neighbor(x, (2*H,2*W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import pylab as pl\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "import numpy as np\n",
    "#import theano as T\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "#import theano.tensor as T\n",
    "np.random.seed(1337) # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "#import keras.layers.containers as containers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "import keras.models as models\n",
    "#import keras.layers.containers as containers\n",
    "from keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape,  Permute\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = './CamVid/'\n",
    "data_shape = 360*480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching \n",
    "I equalized histograms of rbg layers separately, so that change in lighting doesnt effect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(rgb):\n",
    "    #return rgb/255.0\n",
    "    norm=np.zeros((rgb.shape[0], rgb.shape[1], 3),np.float32)\n",
    "\n",
    "    b=rgb[:,:,0]\n",
    "    g=rgb[:,:,1]\n",
    "    r=rgb[:,:,2]\n",
    "\n",
    "    norm[:,:,0]=cv2.equalizeHist(b)\n",
    "    norm[:,:,1]=cv2.equalizeHist(g)\n",
    "    norm[:,:,2]=cv2.equalizeHist(r)\n",
    "\n",
    "    return norm\n",
    "\n",
    "def binarylab(labels):\n",
    "    x = np.zeros([360,480,12])    \n",
    "    for i in range(360):\n",
    "        for j in range(480):\n",
    "            x[i,j,labels[i][j]]=1\n",
    "    return x\n",
    "\n",
    "def prep_data():\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    import os\n",
    "    with open(path+'train.txt') as f:\n",
    "        txt = f.readlines()\n",
    "        txt = [line.split(' ') for line in txt]\n",
    "    print(len(txt))\n",
    "    for i in range(367):#len(txt)\n",
    "        ## these paths are very specific to my machine\n",
    "        train_data.append(normalized(cv2.imread(os.getcwd() + txt[i][0][7:])))#np.rollaxis(,2)\n",
    "        train_label.append(binarylab(cv2.imread(os.getcwd() + txt[i][1][7:][:-1])[:,:,0]))\n",
    "        print('.',end='')\n",
    "    return np.array(train_data), np.array(train_label)\n",
    "\n",
    "train_data, train_label = prep_data()\n",
    "\n",
    "train_label = np.reshape(train_label,(367,data_shape,12))#367\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Compiling neuralnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape=360*480\n",
    "def encoder():\n",
    "        kernel = 3\n",
    "        filter_size = 64\n",
    "        pad = 1\n",
    "        pool_size = 2\n",
    "    \n",
    "        E = Sequential()\n",
    "        \n",
    "        E.add(Layer(input_shape=(360, 480,1)))\n",
    "        E.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "        \n",
    "        E.add(Convolution2D(filter_size, (kernel, kernel), border_mode='valid'))\n",
    "        E.add(BatchNormalization())\n",
    "        E.add(Activation('relu'))\n",
    "        E.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "        \n",
    "        E.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "        E.add(Convolution2D(128, kernel, kernel, border_mode='valid'))\n",
    "        E.add(BatchNormalization())\n",
    "        E.add(Activation('relu'))\n",
    "        E.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "        \n",
    "        E.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "        E.add(Convolution2D(256, kernel, kernel, border_mode='valid'))\n",
    "        E.add(BatchNormalization())\n",
    "        E.add(Activation('relu'))\n",
    "        E.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "        E.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "        E.add(Convolution2D(512, kernel, kernel, border_mode='valid'))\n",
    "        E.add(BatchNormalization())\n",
    "        \n",
    "        E.add(Activation('relu'))\n",
    "        #E.summary()\n",
    "\n",
    "        return E\n",
    "    \n",
    "def decoder():\n",
    "    \n",
    "        kernel = 3\n",
    "        filter_size = 64\n",
    "        pad = 1\n",
    "        pool_size = 2\n",
    "        \n",
    "        D = Sequential()\n",
    "        \n",
    "        D.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "        D.add(Convolution2D(512, kernel, kernel, border_mode='valid'))\n",
    "        D.add(BatchNormalization())\n",
    "\n",
    "        #D.add(UnPooling2D(poolsize=(pool_size,pool_size)))\n",
    "        D.add(UpSampling2D())\n",
    "        \n",
    "        D.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "        D.add(Convolution2D(256, kernel, kernel, border_mode='valid'))\n",
    "        D.add(BatchNormalization())\n",
    "\n",
    "        #D.add(UnPooling2D(poolsize=(pool_size,pool_size)))\n",
    "        D.add(UpSampling2D())\n",
    "        D.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "        D.add(Convolution2D(128, kernel, kernel, border_mode='valid'))\n",
    "        D.add(BatchNormalization())\n",
    "\n",
    "        #D.add(UnPooling2D(poolsize=(pool_size,pool_size)))\n",
    "        D.add(UpSampling2D())\n",
    "        D.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "        D.add(Convolution2D(filter_size, kernel, kernel, border_mode='valid'))\n",
    "        D.add(BatchNormalization())\n",
    "        #D.summary()\n",
    "    \n",
    "        return D\n",
    "    \n",
    "def reshapeData() :\n",
    "    dataReshape = Sequential()\n",
    "    dataReshape.add(Convolution2D(12, 1, 1, border_mode='valid',))\n",
    "    dataReshape.add(Reshape((12,data_shape)))\n",
    "    dataReshape.add(Permute((2, 1)))\n",
    "    dataReshape.add(Activation('softmax'))\n",
    "    return dataReshape\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(encoder())\n",
    "model.add(decoder())\n",
    "model.add(reshapeData())\n",
    "model.summary()\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer='adadelta')\n",
    "model.compile(loss='sparse_categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', # using the Adam optimiser\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 5\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit(np.array(X_train), np.array(Y_train), batch_size=batch_size, nb_epoch=nb_epoch, verbose=1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot((history.history['loss']))\n",
    "plt.plot((history.history['val_loss']))\n",
    "plt.title('Model loss by epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot((history.history['loss']))\n",
    "plt.plot((history.history['val_loss']))\n",
    "plt.title('Model loss from 500 to 2000')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='right')\n",
    "plt.xlim((500, 2000))\n",
    "plt.ylim((50000, 160000))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
